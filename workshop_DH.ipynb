{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f96bb69",
   "metadata": {},
   "source": [
    "Dylan Hastings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-transparency",
   "metadata": {},
   "source": [
    "# 1. Sentiment analysis\n",
    "\n",
    "Using the [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/), we want to do a regression model that predict the ratings are on a 1-10 scale. You have an example train and test set in the `dataset` folder.\n",
    "\n",
    "### 1.1 Regression Model\n",
    "\n",
    "Use a feedforward neural network and NLP techniques we've seen up to now to train the best model you can on this dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ffcba143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Embedding, GRU, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.random import set_seed\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6689b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train_neg = listdir('data/aclImdb/train/neg')\n",
    "files_train_pos = listdir('data/aclImdb/train/pos')\n",
    "\n",
    "files_test_neg = listdir('data/aclImdb/test/neg')\n",
    "files_test_pos = listdir('data/aclImdb/test/pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0dadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(target, reviews, directory):\n",
    "    x = []\n",
    "    x_line = []\n",
    "\n",
    "    for file in directory:\n",
    "        with open(f'data/aclImdb/{target}/{reviews}/{file}', encoding='utf8') as opened_file:\n",
    "            rating = file.split(\"_\")[1].split(\".\")[0]\n",
    "            for line in opened_file:\n",
    "                x_line = []\n",
    "                x_line.append(line)\n",
    "                x_line.append(rating)\n",
    "                x.append(x_line)\n",
    "                \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e807ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg = pd.DataFrame(columns = ['review', 'rating'], data=get_reviews(\"train\", \"neg\", files_train_neg))\n",
    "train_pos = pd.DataFrame(columns = ['review', 'rating'], data=get_reviews(\"train\", \"pos\", files_train_pos))\n",
    "\n",
    "test_neg = pd.DataFrame(columns = ['review', 'rating'], data=get_reviews(\"test\", \"neg\", files_test_neg))\n",
    "test_pos = pd.DataFrame(columns = ['review', 'rating'], data=get_reviews(\"test\", \"pos\", files_test_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58feb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_pos, train_neg], ignore_index=True)\n",
    "test_df = pd.concat([test_pos, test_neg], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d264a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review rating\n",
       "0      Bromwell High is a cartoon comedy. It ran at t...      9\n",
       "1      Homelessness (or Houselessness as George Carli...      8\n",
       "2      Brilliant over-acting by Lesley Ann Warren. Be...     10\n",
       "3      This is easily the most underrated film inn th...      7\n",
       "4      This is not the typical Mel Brooks film. It wa...      8\n",
       "...                                                  ...    ...\n",
       "24995  Towards the end of the movie, I felt it was to...      4\n",
       "24996  This is the kind of movie that my enemies cont...      3\n",
       "24997  I saw 'Descent' last night at the Stockholm Fi...      3\n",
       "24998  Some films that you pick up for a pound turn o...      1\n",
       "24999  This is one of the dumbest films, I've ever se...      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e50d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "pca = PCA(n_components = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aa97815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.sample(n=1000, random_state = 42).reset_index(drop=True)\n",
    "df.rating = df.rating.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc854b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review = df.review.apply(lambda t: \" \".join([t for t in t.replace(\"<br /> \", \"\").lower().split(\" \") if not t in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbca5cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = text.TfidfVectorizer()\n",
    "X = tf.fit_transform(df['review'])\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d94cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddc2ca1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>rev_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>panic streets richard widmark plays u.s. navy ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[0.09635181945360419, -0.06352997017281335, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ask first one really better one. look sarah m....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.0896921085977124, 0.05355772542352921, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan faerie tale theatre i've seen one best...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[-0.11287535096311527, 0.040346814693369364, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  panic streets richard widmark plays u.s. navy ...     8.0   \n",
       "1  ask first one really better one. look sarah m....     1.0   \n",
       "2  big fan faerie tale theatre i've seen one best...    10.0   \n",
       "\n",
       "                                           rev_tfidf  \n",
       "0  [0.09635181945360419, -0.06352997017281335, 0....  \n",
       "1  [-0.0896921085977124, 0.05355772542352921, 0.0...  \n",
       "2  [-0.11287535096311527, 0.040346814693369364, -...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rev_tfidf'] = [x for x in X]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5f45f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_stopper = EarlyStopping(monitor = 'loss', patience = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35003df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape = X.shape[-1]))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bb1e42d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1000/1000 [==============================] - 1s 812us/step - loss: 21.1150 - accuracy: 0.1628\n",
      "Epoch 2/25\n",
      "1000/1000 [==============================] - 1s 785us/step - loss: 5.9890 - accuracy: 0.1831\n",
      "Epoch 3/25\n",
      "1000/1000 [==============================] - 1s 821us/step - loss: 4.6591 - accuracy: 0.1638\n",
      "Epoch 4/25\n",
      "1000/1000 [==============================] - 1s 852us/step - loss: 3.9674 - accuracy: 0.15630s - loss: 3.9257 - accuracy: 0.\n",
      "Epoch 5/25\n",
      "1000/1000 [==============================] - 1s 808us/step - loss: 3.6589 - accuracy: 0.1616\n",
      "Epoch 6/25\n",
      "1000/1000 [==============================] - 1s 946us/step - loss: 3.6330 - accuracy: 0.1749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fc85b59d30>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed(42)\n",
    "set_seed(42)\n",
    "model.fit(x = X, y= df.rating, batch_size = 1, epochs = 25, callbacks = [loss_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1fde607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test_df.sample(n = 1000, random_state = 42).reset_index(drop = True)\n",
    "df_test.rating = df_test.rating.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21eeb58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = tf.fit_transform(df_test['review'])\n",
    "Xt = Xt.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fcd1ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = pca.fit_transform(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ad1f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(Xt)\n",
    "preds = preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ff42382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.636244051395198"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(preds, df_test.rating.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2bf3dd",
   "metadata": {},
   "source": [
    "### 1.2 RNN model\n",
    "\n",
    "Train a RNN to do the sentiment analysis regression. The RNN should consist simply of an embedding layer (to make word IDs into word vectors) a recurrent blocks (GRU or LSTM) feeding into an output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01d1a8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_tag(token):\n",
    "    tags = []\n",
    "    \n",
    "    for tag in nltk.pos_tag(token):\n",
    "        tags.append(tag[1])\n",
    "        \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "146196a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df.sample(n = 1000, random_state = 42).reset_index(drop = True)\n",
    "df.rating = df.rating.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1f11d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rev_token'] = df['review'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93e207ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>rev_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Panic In The Streets Richard Widmark plays ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[In, Panic, In, The, Streets, Richard, Widmark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you ask me the first one was really better ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[If, you, ask, me, the, first, one, was, reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a big fan a Faerie Tale Theatre and I've ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[I, am, a, big, fan, a, Faerie, Tale, Theatre,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I just finished reading a book about Dillinger...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[I, just, finished, reading, a, book, about, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Greg Davis and Bryan Daly take some crazed sta...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[Greg, Davis, and, Bryan, Daly, take, some, cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>According to IMDb, as well as to every other w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[According, to, IMDb, ,, as, well, as, to, eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>In Cold Blood was one of several 60s films tha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[In, Cold, Blood, was, one, of, several, 60s, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I work in a library and expected to like this ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[I, work, in, a, library, and, expected, to, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>This is one of the first films I can remember,...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[This, is, one, of, the, first, films, I, can,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Excellent political thriller, played much quie...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[Excellent, political, thriller, ,, played, mu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  rating  \\\n",
       "0    In Panic In The Streets Richard Widmark plays ...     8.0   \n",
       "1    If you ask me the first one was really better ...     1.0   \n",
       "2    I am a big fan a Faerie Tale Theatre and I've ...    10.0   \n",
       "3    I just finished reading a book about Dillinger...     1.0   \n",
       "4    Greg Davis and Bryan Daly take some crazed sta...     2.0   \n",
       "..                                                 ...     ...   \n",
       "995  According to IMDb, as well as to every other w...     4.0   \n",
       "996  In Cold Blood was one of several 60s films tha...     4.0   \n",
       "997  I work in a library and expected to like this ...     7.0   \n",
       "998  This is one of the first films I can remember,...     7.0   \n",
       "999  Excellent political thriller, played much quie...     8.0   \n",
       "\n",
       "                                             rev_token  \n",
       "0    [In, Panic, In, The, Streets, Richard, Widmark...  \n",
       "1    [If, you, ask, me, the, first, one, was, reall...  \n",
       "2    [I, am, a, big, fan, a, Faerie, Tale, Theatre,...  \n",
       "3    [I, just, finished, reading, a, book, about, D...  \n",
       "4    [Greg, Davis, and, Bryan, Daly, take, some, cr...  \n",
       "..                                                 ...  \n",
       "995  [According, to, IMDb, ,, as, well, as, to, eve...  \n",
       "996  [In, Cold, Blood, was, one, of, several, 60s, ...  \n",
       "997  [I, work, in, a, library, and, expected, to, l...  \n",
       "998  [This, is, one, of, the, first, films, I, can,...  \n",
       "999  [Excellent, political, thriller, ,, played, mu...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "019f8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS:\n",
      "LEXICON SAMPLE (22518 total items):\n",
      "{'In': 2, 'Panic': 3, 'The': 4, 'Streets': 5, 'Richard': 6, 'Widmark': 7, 'plays': 8, 'U.S.': 9, 'Navy': 10, 'doctor': 11, 'who': 12, 'has': 13, 'his': 14, 'week': 15, 'rudely': 16, 'interrupted': 17, 'with': 18, 'a': 19, 'corpse': 20, 'that': 21}\n"
     ]
    }
   ],
   "source": [
    "def make_lexicon(token_seqs, min_freq=1):\n",
    "    '''Create a lexicon for the words in the sentences as well as the tags'''\n",
    "    # First, count how often each word appears in the text.\n",
    "    token_counts = {}\n",
    "    for seq in token_seqs:\n",
    "        for token in seq:\n",
    "            if token in token_counts:\n",
    "                token_counts[token] += 1\n",
    "            else:\n",
    "                token_counts[token] = 1\n",
    "\n",
    "    # Then, assign each word to a numerical index. Filter words that occur less than min_freq times.\n",
    "    lexicon = [token for token, count in token_counts.items() if count >= min_freq]\n",
    "    # Indices start at 1. 0 is reserved for padding, and 1 is reserved for unknown words.\n",
    "    lexicon = {token:idx + 2 for idx,token in enumerate(lexicon)}\n",
    "    lexicon[u'<UNK>'] = 1 # Unknown words are those that occur fewer than min_freq times\n",
    "    lexicon_size = len(lexicon)\n",
    "\n",
    "    print(\"LEXICON SAMPLE ({} total items):\".format(len(lexicon)))\n",
    "    print(dict(list(lexicon.items())[:20]))\n",
    "    \n",
    "    return lexicon\n",
    "\n",
    "print(\"WORDS:\")\n",
    "words_lexicon = make_lexicon(df['rev_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "62957065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_token</th>\n",
       "      <th>Sentence_Idxs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[In, Panic, In, The, Streets, Richard, Widmark...</td>\n",
       "      <td>[2, 3, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[If, you, ask, me, the, first, one, was, reall...</td>\n",
       "      <td>[215, 259, 260, 261, 32, 155, 262, 65, 178, 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[I, am, a, big, fan, a, Faerie, Tale, Theatre,...</td>\n",
       "      <td>[95, 315, 19, 314, 316, 19, 317, 318, 319, 56,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I, just, finished, reading, a, book, about, D...</td>\n",
       "      <td>[95, 276, 362, 363, 19, 364, 238, 365, 24, 165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Greg, Davis, and, Bryan, Daly, take, some, cr...</td>\n",
       "      <td>[420, 421, 56, 422, 423, 424, 72, 425, 426, 67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[This, really, is, an, incredible, film, ., No...</td>\n",
       "      <td>[165, 178, 148, 51, 495, 156, 24, 496, 398, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[If, you, lived, through, the, 60s, ,, this, f...</td>\n",
       "      <td>[215, 259, 610, 611, 32, 612, 45, 162, 156, 96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[As, a, writer, I, find, films, this, bad, mak...</td>\n",
       "      <td>[25, 19, 657, 95, 54, 658, 162, 659, 660, 115,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[I, 'm, 14, years, old, and, I, love, this, ca...</td>\n",
       "      <td>[95, 203, 746, 747, 345, 56, 95, 350, 162, 748...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[This, film, would, usually, classify, as, the...</td>\n",
       "      <td>[165, 156, 175, 791, 792, 106, 32, 311, 290, 4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           rev_token  \\\n",
       "0  [In, Panic, In, The, Streets, Richard, Widmark...   \n",
       "1  [If, you, ask, me, the, first, one, was, reall...   \n",
       "2  [I, am, a, big, fan, a, Faerie, Tale, Theatre,...   \n",
       "3  [I, just, finished, reading, a, book, about, D...   \n",
       "4  [Greg, Davis, and, Bryan, Daly, take, some, cr...   \n",
       "5  [This, really, is, an, incredible, film, ., No...   \n",
       "6  [If, you, lived, through, the, 60s, ,, this, f...   \n",
       "7  [As, a, writer, I, find, films, this, bad, mak...   \n",
       "8  [I, 'm, 14, years, old, and, I, love, this, ca...   \n",
       "9  [This, film, would, usually, classify, as, the...   \n",
       "\n",
       "                                       Sentence_Idxs  \n",
       "0  [2, 3, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  \n",
       "1  [215, 259, 260, 261, 32, 155, 262, 65, 178, 26...  \n",
       "2  [95, 315, 19, 314, 316, 19, 317, 318, 319, 56,...  \n",
       "3  [95, 276, 362, 363, 19, 364, 238, 365, 24, 165...  \n",
       "4  [420, 421, 56, 422, 423, 424, 72, 425, 426, 67...  \n",
       "5  [165, 178, 148, 51, 495, 156, 24, 496, 398, 11...  \n",
       "6  [215, 259, 610, 611, 32, 612, 45, 162, 156, 96...  \n",
       "7  [25, 19, 657, 95, 54, 658, 162, 659, 660, 115,...  \n",
       "8  [95, 203, 746, 747, 345, 56, 95, 350, 162, 748...  \n",
       "9  [165, 156, 175, 791, 792, 106, 32, 311, 290, 4...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Make a dictionary where the string representation of a lexicon item can be retrieved from its numerical index'''\n",
    "\n",
    "def get_lexicon_lookup(lexicon):\n",
    "    '''Make a dictionary where the string representation \n",
    "        of a lexicon item can be retrieved \n",
    "        from its numerical index\n",
    "    '''\n",
    "    lexicon_lookup = {idx: lexicon_item for lexicon_item, idx in lexicon.items()}\n",
    "    print(\"LEXICON LOOKUP SAMPLE:\")\n",
    "    print(dict(list(lexicon_lookup.items())[:20]))\n",
    "    return lexicon_lookup\n",
    "\n",
    "def tokens_to_idxs(token_seqs, lexicon):\n",
    "    idx_seqs = [[lexicon[token] if token in lexicon else lexicon['<UNK>'] for token in token_seq]  \n",
    "                                                                     for token_seq in token_seqs]\n",
    "    return idx_seqs\n",
    "\n",
    "df['Sentence_Idxs'] = tokens_to_idxs(df['rev_token'], words_lexicon)\n",
    "df[['rev_token', 'Sentence_Idxs']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a00e0807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS:\n",
      " [[   0    0    0 ...   80  258   24]\n",
      " [   0    0    0 ...  314  280   24]\n",
      " [   0    0    0 ...  213  361   24]\n",
      " ...\n",
      " [   0    0    0 ...  417  263   24]\n",
      " [   0    0    0 ...  152 7135 1172]\n",
      " [   0    0    0 ...   56 6176   24]]\n",
      "SHAPE: (1000, 1458) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def pad_idx_seqs(idx_seqs, max_seq_len):\n",
    "    # Keras provides a convenient padding function; \n",
    "    padded_idxs = pad_sequences(sequences=idx_seqs, maxlen=max_seq_len)\n",
    "    return padded_idxs\n",
    "\n",
    "max_seq_len = max([len(idx_seq) for idx_seq in df['Sentence_Idxs']]) # Get length of longest sequence\n",
    "train_padded_words = pad_idx_seqs(df['Sentence_Idxs'], \n",
    "                                  max_seq_len + 1) #Add one to max length for offsetting sequence by 1\n",
    "\n",
    "print(\"WORDS:\\n\", train_padded_words)\n",
    "print(\"SHAPE:\", train_padded_words.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a44a6e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create the model'''\n",
    "\n",
    "def create_model(seq_input_len, n_input_nodes, n_embedding_nodes,\n",
    "                 n_hidden_nodes, stateful=False, batch_size=20):\n",
    "    \n",
    "    #Layer 1\n",
    "    input_layer = Input(shape=(None,))\n",
    "    \n",
    "    # Layer 2\n",
    "    embedding_layer = Embedding(input_dim=n_input_nodes,\n",
    "                                output_dim=n_embedding_nodes,\n",
    "                                mask_zero=True)(input_layer) #mask_zero tells the model to ignore 0 values (padding)\n",
    "    #Output shape = (batch_size, input_matrix_length, n_embedding_nodes)\n",
    "    \n",
    "    # Layer 3\n",
    "    gru_layer = GRU(units=n_hidden_nodes)(embedding_layer)\n",
    "    #Output shape = (batch_size, n_hidden_nodes)\n",
    "    #Layer 4\n",
    "    \n",
    "    output_layer = Dense(units=1)(gru_layer)\n",
    "    #Output shape = (batch_size, 1)\n",
    "    #Specify which layers are input and output, compile model with loss and optimization functions\n",
    "    model = Model(inputs=[input_layer], outputs=output_layer)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f57dd70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(seq_input_len=train_padded_words.shape[-1] - 1, #substract 1 from matrix length because of offset\n",
    "                     n_input_nodes=len(words_lexicon) + 1, #Add one for 0 padding\n",
    "                     n_embedding_nodes=300,\n",
    "                     n_hidden_nodes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "71f03322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 1419s 29s/step - loss: 35.9020\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 884s 18s/step - loss: 11.5293\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 1384s 28s/step - loss: 5.4813\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 910s 18s/step - loss: 2.4545\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 3078s 62s/step - loss: 1.4550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fceac251c0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_padded_words[:,1:],\n",
    "          y = df.rating,\n",
    "          batch_size=20,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bafc2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_pos, test_neg], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "00afd745",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.sample(n=1000, random_state = 42).reset_index(drop = True)\n",
    "test_df['rev_token'] = test_df['review'].apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee3e12e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEXICON SAMPLE (22283 total items):\n",
      "{'Wow': 2, '!': 3, 'What': 4, 'a': 5, 'movie': 6, 'if': 7, 'you': 8, 'want': 9, 'to': 10, 'blow': 11, 'your': 12, 'budget': 13, 'on': 14, 'the': 15, 'title': 16, 'and': 17, 'have': 18, 'it': 19, 'look': 20, 'real': 21}\n"
     ]
    }
   ],
   "source": [
    "test_rev_lexicon = make_lexicon(test_df['rev_token'])\n",
    "\n",
    "test_df['Sentence_Idxs'] = tokens_to_idxs(test_df['rev_token'], test_rev_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f2fda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = max([len(idx_seq) for idx_seq in test_df['Sentence_Idxs']])\n",
    "\n",
    "test_padded_words = pad_idx_seqs(test_df['Sentence_Idxs'], max_seq_len + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24919947",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_padded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "689aec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.174605884589652"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(preds, test_df.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-chosen",
   "metadata": {},
   "source": [
    "# 2. (evil) XOR Problem\n",
    "\n",
    "Train an LSTM to solve the XOR problem: that is, given a sequence of bits, determine its parity. The LSTM should consume the sequence, one bit at a time, and then output the correct answer at the sequence’s end. Test the two approaches below:\n",
    "\n",
    "### 2.1 \n",
    "\n",
    "Generate a dataset of random <=100,000 binary strings of equal length <= 50. Train the LSTM; what is the maximum length you can train up to with precisison?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "56431e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 50\n",
    "COUNT = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "60c332fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape check: (100000, 50, 2) = (100000, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "bin_pair = lambda x: [x, not(x)]\n",
    "training = np.array([[bin_pair(random.choice([0, 1])) for _ in range(SEQ_LEN)] for _ in range(COUNT)])\n",
    "target = np.array([[bin_pair(x) for x in np.cumsum(example[:,0]) % 2] for example in training])\n",
    "print('shape check:', training.shape, '=', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5ebd46d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape = (SEQ_LEN, 2), dtype = 'float32'))\n",
    "\n",
    "model.add(LSTM(1, return_sequences = True))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59772a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 12s 12ms/step - loss: 0.6934 - accuracy: 0.4973\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.6930 - accuracy: 0.5081\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.6627 - accuracy: 0.5725\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2481 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 10s 13ms/step - loss: 0.1554 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.1120 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0847 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0655 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.0513 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.0405 - accuracy: 1.0000\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 50, 1)             16        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50, 2)             4         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(training, target, epochs = 10, batch_size = 128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "377b8615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly selected sequence: [0 1 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 1 1 1 0 0 1 1 0 0 0 1 0]\n",
      "prediction: 1\n",
      "confidence: 99.98%\n",
      "actual: 1\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(training)\n",
    "i = random.randint(0, COUNT)\n",
    "chance = predictions[i, -1, 0]\n",
    "print('randomly selected sequence:', training[i, :, 0])\n",
    "print('prediction:', int(chance > 0.5))\n",
    "print('confidence: {:0.2f}%'.format((chance if chance > 0.5 else 1 - chance) * 100))\n",
    "print('actual:', np.sum(training[i, :, 0]) %2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a46415",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "\n",
    "Generate a dataset of random <=200,000 binary strings, where the length of each string is independently and randomly chosen between 1 and 50. Train the LSTM. Does it succeed? What explains the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "db942038",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 200_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dda9a902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape check: (200000, 50, 2) = (200000, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "bin_pair = lambda x: [x, not(x)]\n",
    "training = np.array([[bin_pair(random.choice([0, 1])) for _ in range(SEQ_LEN)] for _ in range(COUNT)])\n",
    "target = np.array([[bin_pair(x) for x in np.cumsum(example[:,0]) % 2] for example in training])\n",
    "print('shape check:', training.shape, '=', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8a332113",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape = (SEQ_LEN, 2), dtype = 'float32'))\n",
    "\n",
    "model.add(LSTM(1, return_sequences = True))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c3941306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 22s 13ms/step - loss: 0.6934 - accuracy: 0.49850s - los\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.6490 - accuracy: 0.5816\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.2007 - accuracy: 0.9999\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.1029 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.0605 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 20s 12ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 50, 1)             16        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50, 2)             4         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(training, target, epochs = 10, batch_size = 128)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6421e9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly selected sequence: [1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 1 0 0]\n",
      "prediction: 1\n",
      "confidence: 100.00%\n",
      "actual: 1\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(training)\n",
    "i = random.randint(0, COUNT)\n",
    "chance = predictions[i, -1, 0]\n",
    "print('randomly selected sequence:', training[i, :, 0])\n",
    "print('prediction:', int(chance > 0.5))\n",
    "print('confidence: {:0.2f}%'.format((chance if chance > 0.5 else 1 - chance) * 100))\n",
    "print('actual:', np.sum(training[i, :, 0]) %2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0d925e",
   "metadata": {},
   "source": [
    "With a dataset of 200,000 binary strings, the model now predicts with 100% confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340fa7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
